{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing the Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the data and Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_master = pd.read_csv('bike_full.csv', dtype={5: str, 7: str})  # Convert both columns to strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_master_clean = bike_master.copy()\n",
    "\n",
    "# Convert datetime columns\n",
    "bike_master_clean['started_at'] = pd.to_datetime(bike_master_clean['started_at'])\n",
    "bike_master_clean['ended_at'] = pd.to_datetime(bike_master_clean['ended_at'])\n",
    "\n",
    "# Convert category columns\n",
    "category_columns = ['rideable_type', 'start_station_name', 'end_station_name', 'member_casual']\n",
    "for col in category_columns:\n",
    "    bike_master_clean[col] = bike_master_clean[col].astype('category')\n",
    "\n",
    "# Convert string columns (IDs)\n",
    "string_columns = ['ride_id', 'start_station_id', 'end_station_id']\n",
    "for col in string_columns:\n",
    "    bike_master_clean[col] = bike_master_clean[col].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "start_station_name       860\n",
       "end_station_name         865\n",
       "start_station_id        1321\n",
       "end_station_id          1338\n",
       "start_lat             570110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding unique values for few columns\n",
    "bike_master_clean[['start_station_name', 'end_station_name', 'start_station_id', 'end_station_id','start_lat']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the dataset: 4467334\n"
     ]
    }
   ],
   "source": [
    "#create a new column for month year\n",
    "bike_master_clean['month_year'] = bike_master_clean['started_at'].dt.to_period('M')\n",
    "\n",
    "#create a new column for year\n",
    "bike_master_clean['year'] = bike_master_clean['started_at'].dt.year\n",
    "\n",
    "#create a new dataframe for the month june 2023 to december 2023\n",
    "bike_master_clean_2023 = bike_master_clean[(bike_master_clean['year'] == 2023)]\n",
    "\n",
    "row_count = len(bike_master_clean_2023)\n",
    "print(f\"Number of rows in the dataset: {row_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize stations\n",
    "def categorize_station_location(lat, lng):\n",
    "    regions = {\n",
    "        'Washington DC': {'lat': (38.8, 39.0), 'lng': (-77.12, -76.9)},\n",
    "        'Arlington': {'lat': (38.8, 38.93), 'lng': (-77.17, -77.03)},\n",
    "        'Alexandria': {'lat': (38.77, 38.85), 'lng': (-77.15, -77.03)},\n",
    "        'Montgomery County': {'lat': (38.95, 39.2), 'lng': (-77.3, -76.9)},\n",
    "        \"Prince George's County\": {'lat': (38.8, 39.1), 'lng': (-76.95, -76.7)},\n",
    "        'Fairfax County': {'lat': (38.7, 39.0), 'lng': (-77.4, -77.15)}\n",
    "    }\n",
    "    \n",
    "    for region, bounds in regions.items():\n",
    "        if (bounds['lat'][0] <= lat <= bounds['lat'][1] and \n",
    "            bounds['lng'][0] <= lng <= bounds['lng'][1]):\n",
    "            return region\n",
    "    return 'Other'\n",
    "\n",
    "# Apply function to classify each start station\n",
    "bike_master_clean_2023.loc[:, 'region'] = bike_master_clean_2023.apply(\n",
    "    lambda row: categorize_station_location(row['start_lat'], row['start_lng']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the region column to category\n",
    "bike_master_clean_2023['region'] = bike_master_clean_2023['region'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id               0\n",
      "rideable_type         0\n",
      "started_at            0\n",
      "ended_at              0\n",
      "start_station_name    0\n",
      "start_station_id      0\n",
      "end_station_name      0\n",
      "end_station_id        0\n",
      "start_lat             0\n",
      "start_lng             0\n",
      "end_lat               0\n",
      "end_lng               0\n",
      "member_casual         0\n",
      "month_year            0\n",
      "year                  0\n",
      "region                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#find missing null values\n",
    "print(bike_master_clean_2023.isnull().sum())\n",
    "\n",
    "#drop missing values\n",
    "bike_master_clean_2023 = bike_master_clean_2023.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3864783 entries, 6226664 to 10693995\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Dtype         \n",
      "---  ------              -----         \n",
      " 0   ride_id             string        \n",
      " 1   rideable_type       category      \n",
      " 2   started_at          datetime64[ns]\n",
      " 3   ended_at            datetime64[ns]\n",
      " 4   start_station_name  category      \n",
      " 5   start_station_id    string        \n",
      " 6   end_station_name    category      \n",
      " 7   end_station_id      string        \n",
      " 8   start_lat           float64       \n",
      " 9   start_lng           float64       \n",
      " 10  end_lat             float64       \n",
      " 11  end_lng             float64       \n",
      " 12  member_casual       category      \n",
      " 13  month_year          period[M]     \n",
      " 14  year                int32         \n",
      " 15  region              category      \n",
      "dtypes: category(5), datetime64[ns](2), float64(4), int32(1), period[M](1), string(3)\n",
      "memory usage: 365.0 MB\n"
     ]
    }
   ],
   "source": [
    "bike_master_clean_2023.isnull().sum()\n",
    "bike_master_clean_2023.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ms/kffv8scn23l62n_5h2kgw9sw0000gn/T/ipykernel_45708/477341846.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  start_station_popularity = bike_master_clean_2023.groupby('start_station_name').size().reset_index(name='start_station_popularity')\n",
      "/var/folders/ms/kffv8scn23l62n_5h2kgw9sw0000gn/T/ipykernel_45708/477341846.py:8: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  end_station_popularity = bike_master_clean_2023.groupby('end_station_name').size().reset_index(name='end_station_popularity')\n",
      "/var/folders/ms/kffv8scn23l62n_5h2kgw9sw0000gn/T/ipykernel_45708/477341846.py:15: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  ride_counts_by_region = bike_master_clean_2023.groupby(['region', 'month_year']).agg({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 114134635.07840584\n",
      "R^2 Score: 0.9889247777661166\n",
      "   Actual Casual Trips  Predicted Casual Trips\n",
      "0               190974               225968.10\n",
      "1                  215                  235.22\n",
      "2                  249                  239.68\n",
      "3                  998                  885.98\n",
      "4                  696                  761.26\n"
     ]
    }
   ],
   "source": [
    "# Data Aggregation\n",
    "bike_master_clean_2023['ride_duration'] = (bike_master_clean_2023['ended_at'] - bike_master_clean_2023['started_at']).dt.total_seconds() / 60  # duration in minutes\n",
    "bike_master_clean_2023['day_of_week'] = bike_master_clean_2023['started_at'].dt.dayofweek\n",
    "bike_master_clean_2023['is_weekend'] = bike_master_clean_2023['day_of_week'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Calculating station popularity\n",
    "start_station_popularity = bike_master_clean_2023.groupby('start_station_name').size().reset_index(name='start_station_popularity')\n",
    "end_station_popularity = bike_master_clean_2023.groupby('end_station_name').size().reset_index(name='end_station_popularity')\n",
    "\n",
    "# Merging station popularity back to the main dataset\n",
    "bike_master_clean_2023 = bike_master_clean_2023.merge(start_station_popularity, on='start_station_name', how='left', suffixes=('_start', '_end'))\n",
    "bike_master_clean_2023 = bike_master_clean_2023.merge(end_station_popularity, on='end_station_name', how='left', suffixes=('_start', '_end'))\n",
    "\n",
    "# Aggregating ride counts by region and month\n",
    "ride_counts_by_region = bike_master_clean_2023.groupby(['region', 'month_year']).agg({\n",
    "    'ride_id': 'count',\n",
    "    'ride_duration': 'mean',\n",
    "    'is_weekend': 'sum',\n",
    "    'start_station_popularity_start': 'mean',\n",
    "    'end_station_popularity_end': 'mean'\n",
    "}).reset_index().rename(columns={'ride_id': 'ride_count'})\n",
    "\n",
    "# Feature Engineering\n",
    "ride_counts_by_region['month'] = ride_counts_by_region['month_year'].dt.month\n",
    "ride_counts_by_region['year'] = ride_counts_by_region['month_year'].dt.year\n",
    "\n",
    "# Encoding the categorical 'region' column\n",
    "ride_counts_by_region = pd.get_dummies(ride_counts_by_region, columns=['region'], drop_first=True)\n",
    "\n",
    "# Defining Features and Target\n",
    "X = ride_counts_by_region.drop(['ride_count', 'month_year'], axis=1)\n",
    "y = ride_counts_by_region['ride_count']\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model Training\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Display Actual vs Predicted Values\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Casual Trips': y_test.values,\n",
    "    'Predicted Casual Trips': y_pred\n",
    "})\n",
    "print(comparison_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Mean Squared Error (MSE) for Casual: 220.71985159421425\n",
      "Optimized R^2 Score for Casual: 0.965891166363356\n",
      "   month rideable_type                                 start_station_name  \\\n",
      "0      4  classic_bike                        New Hampshire Ave & T St NW   \n",
      "1      4  classic_bike                    Columbus Circle / Union Station   \n",
      "2      4  classic_bike                                     15th & P St NW   \n",
      "3      4  classic_bike                                      5th & K St NW   \n",
      "4      4  classic_bike  Eastern Market Metro / Pennsylvania Ave & 8th ...   \n",
      "\n",
      "   ride_count  lag_1  lag_3  predicted_rides  \n",
      "0         565  511.0  456.0           550.71  \n",
      "1         486  614.0  551.0           513.97  \n",
      "2         491  473.0  440.0           497.49  \n",
      "3         481  406.0  358.0           449.93  \n",
      "4         437  407.0  317.0           412.09  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'started_at' to datetime if it's not already\n",
    "bike_master_clean_2023['started_at'] = pd.to_datetime(bike_master_clean_2023['started_at'])\n",
    "\n",
    "# Sample 20% of data while maintaining rideable_type distribution\n",
    "stratified_sample, _ = train_test_split(bike_master_clean_2023, test_size=0.8, stratify=bike_master_clean_2023['rideable_type'], random_state=42)\n",
    "\n",
    "# Extract month and additional features\n",
    "stratified_sample['month'] = stratified_sample['started_at'].dt.month\n",
    "\n",
    "# Group by month, rideable_type, and start_station_name to get ride counts\n",
    "grouped = (stratified_sample.groupby(['month', 'rideable_type', 'start_station_name'], observed=True)\n",
    "             .size()\n",
    "             .reset_index(name='ride_count'))\n",
    "\n",
    "# Feature engineering\n",
    "# Adding lag features to capture historical trends\n",
    "grouped['lag_1'] = grouped.groupby(['rideable_type', 'start_station_name'], observed=True)['ride_count'].shift(1)\n",
    "grouped['lag_3'] = grouped.groupby(['rideable_type', 'start_station_name'], observed=True)['ride_count'].shift(3)\n",
    "\n",
    "# Drop NaN values created by shifting\n",
    "grouped.dropna(inplace=True)\n",
    "\n",
    "# Define features and target\n",
    "X = grouped[['month', 'lag_1', 'lag_3']]\n",
    "y = grouped['ride_count']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Optimized Mean Squared Error (MSE) for Casual:\", mse)\n",
    "print(f\"Optimized R^2 Score for Casual:\", r2)\n",
    "\n",
    "# Display Actual vs Predicted Values\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Casual Trips': y_test.values,\n",
    "    'Predicted Casual Trips': y_pred\n",
    "})\n",
    "\n",
    "# Predict future trips\n",
    "grouped['predicted_rides'] = model.predict(grouped[['month', 'lag_1', 'lag_3']])\n",
    "\n",
    "# Get top 20 stations with the highest predicted rides\n",
    "top_20_predicted = (grouped.sort_values(['month', 'rideable_type', 'predicted_rides'], ascending=[True, True, False])\n",
    "                                .groupby(['month', 'rideable_type'], observed=True)\n",
    "                                .head(20)\n",
    "                                .reset_index(drop=True))\n",
    "\n",
    "print(top_20_predicted.head())\n",
    "\n",
    "#create tabular data for the top 20 stations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Mean Squared Error (MSE) for Casual: 3359.541645372091\n",
      "Optimized R^2 Score for Casual: 0.9756296067665255\n",
      "   month rideable_type               start_station_name  ride_count   lag_1  \\\n",
      "0      4  classic_bike      New Hampshire Ave & T St NW        2684  2568.0   \n",
      "1      4  classic_bike  Columbus Circle / Union Station        2570  3045.0   \n",
      "2      4  classic_bike                   15th & P St NW        2432  2328.0   \n",
      "3      4  classic_bike                    5th & K St NW        2510  2118.0   \n",
      "4      4  classic_bike                 Lincoln Memorial        2371  1889.0   \n",
      "\n",
      "    lag_3  predicted_rides  \n",
      "0  2323.0          2831.47  \n",
      "1  2613.0          2744.26  \n",
      "2  2124.0          2533.70  \n",
      "3  1784.0          2429.30  \n",
      "4   775.0          2303.48  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'started_at' to datetime if it's not already\n",
    "bike_master_clean_2023['started_at'] = pd.to_datetime(bike_master_clean_2023['started_at'])\n",
    "\n",
    "# Extract month and additional features\n",
    "bike_master_clean_2023['month'] = bike_master_clean_2023['started_at'].dt.month\n",
    "\n",
    "# Group by month, rideable_type, and start_station_name to get ride counts\n",
    "grouped = (bike_master_clean_2023.groupby(['month', 'rideable_type', 'start_station_name'], observed=True)\n",
    "             .size()\n",
    "             .reset_index(name='ride_count'))\n",
    "\n",
    "# Feature engineering\n",
    "# Adding lag features to capture historical trends\n",
    "grouped['lag_1'] = grouped.groupby(['rideable_type', 'start_station_name'], observed=True)['ride_count'].shift(1)\n",
    "grouped['lag_3'] = grouped.groupby(['rideable_type', 'start_station_name'], observed=True)['ride_count'].shift(3)\n",
    "\n",
    "# Drop NaN values created by shifting\n",
    "grouped.dropna(inplace=True)\n",
    "\n",
    "# Define features and target\n",
    "X = grouped[['month', 'lag_1', 'lag_3']]\n",
    "y = grouped['ride_count']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Optimized Mean Squared Error (MSE) for Casual:\", mse)\n",
    "print(f\"Optimized R^2 Score for Casual:\", r2)\n",
    "\n",
    "# Display Actual vs Predicted Values\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Casual Trips': y_test.values,\n",
    "    'Predicted Casual Trips': y_pred\n",
    "})\n",
    "\n",
    "# Predict future trips\n",
    "grouped['predicted_rides'] = model.predict(grouped[['month', 'lag_1', 'lag_3']])\n",
    "\n",
    "# Get top 20 stations with the highest predicted rides\n",
    "top_20_predicted = (grouped.sort_values(['month', 'rideable_type', 'predicted_rides'], ascending=[True, True, False])\n",
    "                                .groupby(['month', 'rideable_type'], observed=True)\n",
    "                                .head(20)\n",
    "                                .reset_index(drop=True))\n",
    "\n",
    "print(top_20_predicted.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Best Hyperparameters: {'bootstrap': True, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 150}\n",
      "Optimized Mean Squared Error (MSE) for Casual: 5.345668442592735\n",
      "Optimized R^2 Score for Casual: 0.5940557953236996\n",
      "          day rideable_type                           start_station_name  \\\n",
      "0  2023-01-08  classic_bike                       4th St & Madison Dr NW   \n",
      "1  2023-01-08  classic_bike                15th St & Constitution Ave NW   \n",
      "2  2023-01-08  classic_bike                    Jefferson Dr & 14th St SW   \n",
      "3  2023-01-08  classic_bike  Henry Bacon Dr & Lincoln Memorial Circle NW   \n",
      "4  2023-01-08  classic_bike                  New Hampshire Ave & T St NW   \n",
      "\n",
      "   day_of_week  month  ride_count  lag_1  lag_7  predicted_rides  \n",
      "0            6      1           7   12.0   20.0        16.474839  \n",
      "1            6      1           5   14.0   17.0        13.921019  \n",
      "2            6      1           3    8.0   17.0        13.158259  \n",
      "3            6      1           3   19.0   14.0        12.071995  \n",
      "4            6      1          11   20.0   12.0        11.803494  \n"
     ]
    }
   ],
   "source": [
    "# Convert 'started_at' to datetime if it's not already\n",
    "bike_master_clean_2023['started_at'] = pd.to_datetime(bike_master_clean_2023['started_at'])\n",
    "\n",
    "# Sample 20% of data while maintaining rideable_type distribution\n",
    "stratified_sample, _ = train_test_split(bike_master_clean_2023, test_size=0.8, stratify=bike_master_clean_2023['rideable_type'], random_state=42)\n",
    "\n",
    "# Extract day and additional features\n",
    "stratified_sample['day'] = stratified_sample['started_at'].dt.date\n",
    "stratified_sample['day_of_week'] = stratified_sample['started_at'].dt.dayofweek\n",
    "stratified_sample['month'] = stratified_sample['started_at'].dt.month\n",
    "\n",
    "# Group by day, rideable_type, start_station_name, day_of_week, and month to get ride counts\n",
    "grouped = (stratified_sample.groupby(['day', 'rideable_type', 'start_station_name', 'day_of_week', 'month'], observed=True)\n",
    "             .size()\n",
    "             .reset_index(name='ride_count'))\n",
    "\n",
    "# Feature engineering\n",
    "# Adding lag features to capture historical trends\n",
    "grouped['lag_1'] = grouped.groupby(['rideable_type', 'start_station_name'], observed=True)['ride_count'].shift(1)\n",
    "grouped['lag_7'] = grouped.groupby(['rideable_type', 'start_station_name'], observed=True)['ride_count'].shift(7)\n",
    "\n",
    "# Drop NaN values created by shifting\n",
    "grouped.dropna(inplace=True)\n",
    "\n",
    "# Define features and target\n",
    "X = grouped[['day_of_week', 'month', 'lag_1', 'lag_7']]\n",
    "y = grouped['ride_count']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Grid Search CV for Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=42),\n",
    "                            param_grid=param_grid,\n",
    "                            cv=3,\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1,\n",
    "                            scoring='r2')\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "\n",
    "# Use the best model for prediction\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Optimized Mean Squared Error (MSE) for Casual:\", mse)\n",
    "print(f\"Optimized R^2 Score for Casual:\", r2)\n",
    "\n",
    "# Display Actual vs Predicted Values\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Casual Trips': y_test.values,\n",
    "    'Predicted Casual Trips': y_pred\n",
    "})\n",
    "\n",
    "# Predict future trips\n",
    "grouped['predicted_rides'] = best_model.predict(grouped[['day_of_week', 'month', 'lag_1', 'lag_7']])\n",
    "\n",
    "# Get top 20 stations with the highest predicted rides\n",
    "top_20_predicted = (grouped.sort_values(['day', 'rideable_type', 'predicted_rides'], ascending=[True, True, False])\n",
    "                                .groupby(['day', 'rideable_type'], observed=True)\n",
    "                                .head(20)\n",
    "                                .reset_index(drop=True))\n",
    "\n",
    "\n",
    "\n",
    "print(top_20_predicted.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAB_V1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
